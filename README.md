# ğŸ” Vision Transformer ile GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma Projesi

Bu proje, **Vision Transformer (ViT)** teknolojisini kullanarak gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma iÅŸlemleri gerÃ§ekleÅŸtiren kapsamlÄ± bir Python uygulamasÄ±dÄ±r. Proje hem sÄ±fÄ±rdan ViT modeli oluÅŸturma hem de Ã¶nceden eÄŸitilmiÅŸ model kullanma yaklaÅŸÄ±mlarÄ±nÄ± iÃ§ermektedir.

## ğŸŒŸ Ã–zellikler

- **ğŸ”§ SÄ±fÄ±rdan ViT Modeli**: Vision Transformer mimarisini sÄ±fÄ±rdan inÅŸa eden kod
- **ğŸš€ Ã–nceden EÄŸitilmiÅŸ Model**: PyTorch'un ViT-B-16 modelini kullanan transfer learning yaklaÅŸÄ±mÄ±
- **ğŸ“Š KapsamlÄ± Test Suite**: TÃ¼m validation veri seti Ã¼zerinde detaylÄ± performans analizi
- **ğŸ“ˆ GÃ¶rselleÅŸtirme**: EÄŸitim grafikleri ve tahmin sonuÃ§larÄ±nÄ±n gÃ¶rsel analizi
- **ğŸ” ModÃ¼ler TasarÄ±m**: Yeniden kullanÄ±labilir kod yapÄ±sÄ±
- **ğŸ“‹ DetaylÄ± Raporlama**: JSON, CSV ve metin formatlarÄ±nda sonuÃ§ raporlarÄ±

## ğŸ—ï¸ Proje YapÄ±sÄ±

```
Image-Classification/
â”œâ”€â”€ ğŸ“ going_modular/           # ModÃ¼ler kod yapÄ±sÄ±
â”‚   â””â”€â”€ going_modular/
â”‚       â”œâ”€â”€ engine.py           # EÄŸitim dÃ¶ngÃ¼sÃ¼
â”‚       â”œâ”€â”€ model_builder.py    # Model oluÅŸturma fonksiyonlarÄ±
â”‚       â”œâ”€â”€ predictions.py      # Tahmin fonksiyonlarÄ±
â”‚       â”œâ”€â”€ train.py           # EÄŸitim scripti
â”‚       â””â”€â”€ utils.py           # YardÄ±mcÄ± fonksiyonlar
â”œâ”€â”€ ğŸ“„ image_classifier_from_scratch.py    # SÄ±fÄ±rdan ViT implementasyonu
â”œâ”€â”€ ğŸ“„ train_using_pretrained_model_image_classifier.py  # Transfer learning
â”œâ”€â”€ ğŸ“„ test_model.py           # Model test ve deÄŸerlendirme
â”œâ”€â”€ ğŸ“„ helper_functions.py     # YardÄ±mcÄ± fonksiyonlar
â””â”€â”€ ğŸ“„ README.md              # Bu dosya
```

## ğŸ§  Vision Transformer Mimarisi

Bu projede implementasyonu yapÄ±lan Vision Transformer aÅŸaÄŸÄ±daki bileÅŸenleri iÃ§erir:

### ğŸ”¹ Ana BileÅŸenler
- **Patch Embedding**: GÃ¶rÃ¼ntÃ¼leri sabit boyutlu patch'lere bÃ¶ler ve embedding vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
- **Multi-Head Self-Attention**: Patch'ler arasÄ± iliÅŸkileri Ã¶ÄŸrenir
- **MLP Blocks**: Feed-forward neural network katmanlarÄ±
- **Transformer Encoder**: Attention ve MLP bloklarÄ±nÄ± birleÅŸtirir
- **Classification Head**: Final sÄ±nÄ±flandÄ±rma katmanÄ±

### ğŸ”¹ Teknik Detaylar
- **Patch Size**: 16x16 piksel
- **Embedding Dimension**: 768
- **Attention Heads**: 12
- **Transformer Layers**: 12
- **MLP Size**: 3072

## ğŸš€ Kurulum ve KullanÄ±m

### Gerekli KÃ¼tÃ¼phaneler

```bash
pip install torch torchvision matplotlib pandas tqdm pillow torchinfo
```

### ğŸ“ Veri YapÄ±sÄ±

Veri setinizi aÅŸaÄŸÄ±daki yapÄ±da organize edin:

```
yazlab-data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class1/
â”‚   â”œâ”€â”€ class2/
â”‚   â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ class1/
    â”œâ”€â”€ class2/
    â””â”€â”€ ...
```

### ğŸƒâ€â™‚ï¸ Modelleri Ã‡alÄ±ÅŸtÄ±rma

#### 1. SÄ±fÄ±rdan ViT Modeli
```bash
python image_classifier_from_scratch.py
```

#### 2. Ã–nceden EÄŸitilmiÅŸ Model ile Transfer Learning
```bash
python train_using_pretrained_model_image_classifier.py
```

#### 3. Model Test ve DeÄŸerlendirme
```bash
python test_model.py
```

## ğŸ“Š Model PerformansÄ±

### ğŸ¯ DeÄŸerlendirme Metrikleri
- **Genel DoÄŸruluk OranÄ±**: TÃ¼m test verisi Ã¼zerindeki baÅŸarÄ±
- **SÄ±nÄ±f BazÄ±nda DoÄŸruluk**: Her sÄ±nÄ±f iÃ§in ayrÄ± performans analizi
- **GÃ¼ven SkorlarÄ±**: Her tahmin iÃ§in gÃ¼ven aralÄ±ÄŸÄ±
- **Confusion Matrix**: DetaylÄ± hata analizi

### ğŸ“ˆ Ã‡Ä±ktÄ± FormatlarÄ±
- **JSON**: DetaylÄ± sonuÃ§lar ve metadata
- **CSV**: Tabular veri analizi iÃ§in
- **GÃ¶rsel**: Tahmin Ã¶rnekleri ve grafikler
- **Metin Raporu**: Ã–zet istatistikler

## ğŸ”§ Ã–zelleÅŸtirme

### Model Hiperparametreleri
```python
# EÄŸitim parametreleri
BATCH_SIZE = 32
LEARNING_RATE = 1e-4
EPOCHS = 10
IMG_SIZE = 224

# ViT parametreleri
patch_size = 16
embedding_dim = 768
num_heads = 12
num_transformer_layers = 12
```

### Veri Augmentasyonu
```python
transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2),
    transforms.ToTensor(),
])
```

## ğŸ“š KullanÄ±lan Teknolojiler

| Teknoloji | Versiyon | AÃ§Ä±klama |
|-----------|----------|----------|
| **PyTorch** | 2.x | Derin Ã¶ÄŸrenme framework'Ã¼ |
| **Torchvision** | 0.15+ | GÃ¶rÃ¼ntÃ¼ iÅŸleme ve pretrained modeller |
| **Transformers** | Custom | Vision Transformer implementasyonu |
| **Matplotlib** | 3.x | Veri gÃ¶rselleÅŸtirme |
| **Pandas** | 1.x | Veri analizi |
| **PIL** | 8.x | GÃ¶rÃ¼ntÃ¼ iÅŸleme |

## ğŸ¤ KatkÄ±da Bulunma

1. Bu repository'yi fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Branch'inizi push edin (`git push origin feature/AmazingFeature`)
5. Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- **Attention Is All You Need** makalesinin yazarlarÄ±
- **An Image is Worth 16x16 Words** makalesinin yazarlarÄ±
- PyTorch ve Torchvision geliÅŸtiricileri
- AÃ§Ä±k kaynak topluluÄŸu

## ğŸ“ Ä°letiÅŸim

Proje hakkÄ±nda sorularÄ±nÄ±z iÃ§in issue aÃ§abilir veya pull request gÃ¶nderebilirsiniz.

---

â­ **Bu projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!** â­
